<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Art of Controlled Noise: Laplace and Exponential Mechanisms in Differential Privacy | Divyanshu Kumar </title> <meta name="author" content="Divyanshu Kumar"> <meta name="description" content="Blog #3 in the series of Inception of Differential Privacy"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.svg?d10861c21807364ff037bb330c80684d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://divyanshugit.github.io/blog/2025/art-of-controlled-noise/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Divyanshu Kumar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Art of Controlled Noise: Laplace and Exponential Mechanisms in Differential Privacy</h1> <p class="post-meta"> Created in March 02, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/differnital-privacy"> <i class="fa-solid fa-hashtag fa-sm"></i> Differnital Privacy</a>     ·   <a href="/blog/category/pets"> <i class="fa-solid fa-tag fa-sm"></i> PETs</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dp_blog/3-480.webp 480w,/assets/img/dp_blog/3-800.webp 800w,/assets/img/dp_blog/3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/dp_blog/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>In previous blogs<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>,<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, we established the necessity of <strong><em>differential privacy (DP)</em></strong> and provided a rigorous mathematical foundation for how it works. Now, let’s focus on the <strong>mechanisms</strong> that implement DP effectively the <strong>Laplace Mechanism</strong> and the <strong>Exponential Mechanism</strong><sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. These methods allow us to inject <strong>noise in a mathematically principled way</strong>, ensuring privacy while preserving as much utility as possible.</p> <h2 id="understanding-sensitivity-and-noise-in-differential-privacy">Understanding Sensitivity and Noise in Differential Privacy</h2> <p>Before diving into the specific mechanisms, it’s important to understand <strong>why adding noise is necessary</strong> in differential privacy. The idea is simple: if the presence or absence of any one individual in a dataset could drastically change the results of a query, then that dataset is at risk of exposing private information.</p> <p>As we already know that and two neighboring datasets that differ by <strong>at most one element</strong>. A mechanism \(M\) satisfies \(\epsilon\)-Differential Privacy if for all possible outputs \(S \subseteq range(M)\):</p> \[P(\mathcal{M}(D) \in S) \leq e^{\epsilon} P(\mathcal{M}(D') \in S) \quad (1)\] <p>This is where <strong>sensitivity</strong> comes into play. Sensitivity measures <strong>how much a function’s output can change</strong> when a single data point is added or removed. Given a function \(f : D \to R\), the \(l_1\)-sensitivity is defined as:</p> \[\Delta f = \max_{D, D'} | f(D) - f(D') | \quad (2)\] <p>This quantifies how much the function’s output can change due to a single individual’s data modification. If a function has <strong>high sensitivity</strong>, it means that one person’s data could have a significant impact on the result. If a function has <strong>low sensitivity</strong>, it means that individual contributions don’t change the overall outcome much.</p> <p>For example:</p> <ul> <li> <p>If we count the number of people in a dataset, adding or removing one person changes the count by <strong>exactly 1</strong>. This means the sensitivity of this function is <strong>1</strong>.</p> </li> <li> <p>If we calculate the <strong>average income</strong> of people in a dataset, adding or removing someone with a very high or low income could <strong>shift the result noticeably</strong>, meaning the function has a <strong>higher sensitivity</strong>.</p> </li> </ul> <p>Since high-sensitivity queries can expose more about individuals, differential privacy combats this by <strong>adding just the right amount of noise</strong> enough to obscure an individual’s influence, but not so much that the data becomes useless. The <strong>Laplace Mechanism</strong> and <strong>Exponential Mechanism</strong> are two ways to achieve this balance.</p> <hr> <h2 id="the-laplace-mechanism-adding-noise-to-numbers">The Laplace Mechanism: Adding Noise to Numbers</h2> <p>The <strong>Laplace Mechanism</strong> is one of the most widely used techniques in differential privacy. It works by <strong>adding noise from the Laplace distribution</strong> to numerical results, ensuring that small changes in the dataset do not reveal any single individual’s data.</p> <h3 id="how-it-works">How It Works</h3> <ol> <li> <p>First, determine the sensitivity of the function—how much the output can change if one person is added or removed.</p> </li> <li> <p>Generate noise using the <strong>Laplace distribution</strong>, which is centered around zero and spreads outwards.</p> </li> <li> <p>Add this noise to the function’s output before sharing the result.</p> </li> </ol> <p>Mathematically, the mechanism can be written as:</p> \[\mathcal{M}_{\text{Lap}}(D) = f(D) + \text{Lap}\left(0, \frac{\Delta f}{\epsilon}\right) \quad (3)\] \[b = \frac{\Delta f}{\epsilon} \quad (4)\] <p>where \(Lap(0, b)\) is a random variable sampled from the Laplace distribution centered at \(0\) with scale parameter \(b\) The probability density function (PDF) of the Laplace distribution is:</p> \[{Lap}(x | b) = \frac{1}{2b} e^{-\frac{|x|}{b}} \quad (5)\] <p>For the Laplace Mechanism to satisfy ε-DP, we must show that for neighboring datasets D and D’, the probability ratio obeys the DP condition:</p> \[\frac{P(\mathcal{M}_{\text{Lap}}(D) = x)}{P(\mathcal{M}_{\text{Lap}}(D') = x)} \leq e^{\epsilon} \quad (6)\] <h3 id="theorem-1">Theorem 1</h3> <p>The laplae mechanism preserves (\(\epsilon, 0\))-differential privacy.</p> <p><strong><em>Proof:</em></strong></p> <p>For two neighbouring datasets \(D\) and \(D'\):</p> \[|f(D) - f(D')| \leq \Delta f \quad (7)\] <p>The probability density of output x given \(D\) and \(D'\) is:</p> \[P(x | D) = \frac{1}{2b} e^{-\frac{|x - f(D)|}{b}} \quad (8)\] \[P(x | D') = \frac{1}{2b} e^{-\frac{|x - f(D')|}{b}} \quad (9)\] <p>Taking the ratio of equation(8) and (9), we get:</p> \[\frac{P(x | D)}{P(x | D')} = e^{\frac{| f(D') - f(D) |}{b}}\] <p>Using the values from equation (4) and (7),</p> \[e^{\frac{| f(D') - f(D) |}{b}} \leq e^{\frac{\Delta f}{\Delta f/\epsilon}} = e^{\epsilon}\] <p>Thus, the Laplace Mechanism satisfies the (\(\epsilon,0\))-DP.</p> <h3 id="example-calculating-the-average-age-privately">Example: Calculating the Average Age Privately</h3> <p>Imagine we want to calculate the average age of employees in a company while preserving their privacy. If the age range is between 20 and 60 years, the worst-case scenario (if one person is added or removed) could shift the average by a few years.</p> <p>To ensure privacy, we:</p> <ol> <li> <p>Compute the real average age.</p> </li> <li> <p>Add noise drawn from a Laplace distribution.</p> </li> <li> <p>Share the noisy result instead of the exact one.</p> </li> </ol> <p>Now, an outsider analyzing the data cannot pinpoint <strong>anyone’s exact age</strong>, but the <strong>overall trend remains accurate</strong>.</p> <blockquote> <p>Laplace Mechanism in <a href="https://github.com/divyanshugit/Inception-of-DP/tree/master/mechanisms#1-laplace-mechanism" rel="external nofollow noopener" target="_blank">action</a></p> </blockquote> <h3 id="when-to-use-the-laplace-mechanism">When to Use the Laplace Mechanism</h3> <ul> <li> <p>When dealing with <strong>numerical queries</strong> like counts, averages, sums, or medians.</p> </li> <li> <p>When the <strong>sensitivity of the function is well understood</strong> and doesn’t change drastically.</p> </li> </ul> <h2 id="the-exponential-mechanism">The Exponential Mechanism</h2> <p>While the Laplace Mechanism works well for numerical outputs, what if we need to <strong>choose from a set of options</strong> rather than return a number? This is where the <strong>Exponential Mechanism</strong> comes in.</p> <p>Instead of <strong>adding noise to numbers</strong>, the <strong>Exponential Mechanism</strong> adds noise to choices by randomly selecting an outcome <strong>based on a utility function</strong>.</p> <h3 id="how-it-works-1">How It Works</h3> <ol> <li> <p>Define a <strong>utility function</strong> that assigns a score to each possible option based on the dataset.</p> </li> <li> <p>Instead of always choosing the best option (which could reveal too much), the mechanism picks <strong>randomly</strong>, but gives higher-scoring options a higher probability.</p> </li> <li> <p>The level of randomness is controlled by \(\epsilon\), just like in the Laplace Mechanism.</p> </li> </ol> <p>Given a dataset \(D\), let \(u(D,r)\) be a utility function that measures the quality of output \(r\). The mechanism selects an output \(r\) with probability:</p> \[P(r | D) \propto \exp\left( \frac{\epsilon u(D, r)}{2 \Delta u} \right) \quad (10)\] <p>Where:</p> <ul> <li> <p>\(u(D,r)\) is the utility function (higher is better)</p> </li> <li> <p>\(\Delta u\) is the sensitivity of the utility function:</p> \[\Delta u = \max_{D, D', r} | u(D, r) - u(D', r) | \quad (11)\] </li> <li> <p>\(\epsilon\) controls the trade-off between randomness and privacy</p> </li> </ul> <h3 id="theorem-2">Theorem 2</h3> <p>The exponential mechanism preserves (\(\epsilon, 0\))-differential privacy.</p> <p><strong><em>Proof:</em></strong></p> <p>For neighbouring datasets \(D\) and \(D'\), we consider the probability ratio of selecting an output \(r\):</p> \[\frac{P(r | D)}{P(r | D')} = \frac{\exp^{\frac{\epsilon u(D, r)}{2 \Delta u}}}{\exp^{\frac{\epsilon u(D', r)}{2 \Delta u}}} = \exp^{\frac{\epsilon ( u(D, r) - u(D', r) )}{2 \Delta u}}\] <p>Since,</p> \[| u(D, r) - u(D', r) | \leq \Delta u\] <p>we get:</p> \[exp^{\frac{\epsilon \Delta u}{2 \Delta u}} = \exp^{\epsilon/2}\] <p>Since this holds for all \(r\), the Exponential Mechanism satisfies (\(\epsilon,0\))-DP</p> <h3 id="example-choosing-a-private-poll-winner">Example: Choosing a Private Poll Winner</h3> <p>Suppose a company is running a <strong>survey</strong> where employees vote on <strong>which workplace perk they prefer</strong>:</p> <ul> <li> <p>Option A: Free Lunch</p> </li> <li> <p>Option B: Gym Membership</p> </li> <li> <p>Option C: Extra Paid Leave</p> </li> </ul> <p>Each option gets a score based on the number of votes, but we don’t want to <strong>directly publish the highest-voted option</strong>(since that might expose individual preferences).</p> <p>Instead, we:</p> <ol> <li> <p>Assign a <strong>utility score</strong> based on votes.</p> </li> <li> <p>Use the <strong>Exponential Mechanism</strong> to <strong>randomly select an option</strong>, favouring those with more votes but still allowing less popular options to have a chance.</p> </li> </ol> <p>This ensures that even if one person’s vote changes, the result doesn’t dramatically shift thus <strong>protecting individual privacy</strong>. Check this out to under</p> <blockquote> <p>Exponential Mechanism in <a href="https://github.com/divyanshugit/Inception-of-DP/tree/master/mechanisms#2-exponential-mechanism" rel="external nofollow noopener" target="_blank">action</a></p> </blockquote> <h4 id="when-to-use-the-exponential-mechanism">When to Use the Exponential Mechanism</h4> <ul> <li> <p>When selecting from a discrete set of choices (e.g., locations, survey answers, recommendations).</p> </li> <li> <p>When privacy is important but the result should still favor the best options.</p> </li> </ul> <h2 id="conclusion">Conclusion</h2> <p>The <strong>Laplace and Exponential Mechanisms</strong> are fundamental in ensuring Differential Privacy. The <strong>Laplace Mechanism</strong> is best suited for numerical queries, where adding carefully calibrated noise preserves privacy without distorting aggregate results. The <strong>Exponential Mechanism</strong>, on the other hand, is ideal for <strong>categorical choices</strong>, ensuring privacy while still favoring the most optimal selections.</p> <p>Both mechanisms rely on a balance between <strong>privacy strength</strong> (controlled by ) and <strong>data utility</strong>, achieved through careful sensitivity analysis and noise injection. Understanding when and how to use these mechanisms is crucial for designing privacy-preserving systems that maintain both security and functionality.</p> <p>By applying these principles, we can continue to extract valuable insights from data while safeguarding individual privacy. In upcoming blogs<sup id="fnref:X" role="doc-noteref"><a href="#fn:X" class="footnote" rel="footnote">4</a></sup>, we’ll transition from data to the machine learning space.</p> <hr> <div style="text-align: center;"> <p><strong>Found this article helpful or have questions? 💡</strong></p> <p>I'm always happy to discuss Differential Privacy, answer your questions, or hear your feedback.</p> <p><strong><a href="mailto:kumardivy1999@gmail.com?subject=Discussion:%20Differential%20Privacy%20Blog%20Series">📧 Click here to send me an email</a></strong></p> </div> <hr> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Kumar, D. (2025). <a href="https://dvynsh.org/blog/2025/differential-privacy-but-why/" rel="external nofollow noopener" target="_blank">Differential Privacy!! But Why?</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>Kumar, D. (2025). <a href="https://dvynsh.org/blog/2025/dp-guarantee-in-action/" rel="external nofollow noopener" target="_blank">DP Guarantee In Action</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:3" role="doc-endnote"> <p>Dwork, C., &amp; Roth, A. <a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf" rel="external nofollow noopener" target="_blank">The Algorithmic Foundations of Differential Privacy - Chapter 2</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:X" role="doc-endnote"> <p>Kumar, D. (2025). <a href="https://github.com/divyanshugit/Inception-of-DP" rel="external nofollow noopener" target="_blank">Upcoming topics in this series / Inception of DP</a> <a href="#fnref:X" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/differential-privacy-but-why/">Differential Privacy!! But Why?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/dp-guarantee-in-action/">DP Guarantee in Action</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/llm-quantization/">Exploring Llama.cpp with Llama Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/interrogate_llm/">🔍 InterrogateLLM: In Search of Truth</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Divyanshu Kumar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-D9VESR00K0"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D9VESR00K0");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>